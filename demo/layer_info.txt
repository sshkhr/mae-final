blocks.0.norm1 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.0.attn <class 'vision_transformer.Attention'>
blocks.0.attn.qkv <class 'torch.nn.modules.linear.Linear'>
blocks.0.attn.proj <class 'torch.nn.modules.linear.Linear'>
blocks.0.norm2 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.0.mlp <class 'vision_transformer.Mlp'>
blocks.0.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>
blocks.0.mlp.act <class 'torch.nn.modules.activation.GELU'>
blocks.0.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>
blocks.1.norm1 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.1.attn <class 'vision_transformer.Attention'>
blocks.1.attn.qkv <class 'torch.nn.modules.linear.Linear'>
blocks.1.attn.proj <class 'torch.nn.modules.linear.Linear'>
blocks.1.norm2 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.1.mlp <class 'vision_transformer.Mlp'>
blocks.1.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>
blocks.1.mlp.act <class 'torch.nn.modules.activation.GELU'>
blocks.1.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>
blocks.2.norm1 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.2.attn <class 'vision_transformer.Attention'>
blocks.2.attn.qkv <class 'torch.nn.modules.linear.Linear'>
blocks.2.attn.proj <class 'torch.nn.modules.linear.Linear'>
blocks.2.norm2 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.2.mlp <class 'vision_transformer.Mlp'>
blocks.2.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>
blocks.2.mlp.act <class 'torch.nn.modules.activation.GELU'>
blocks.2.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>
blocks.3.norm1 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.3.attn <class 'vision_transformer.Attention'>
blocks.3.attn.qkv <class 'torch.nn.modules.linear.Linear'>
blocks.3.attn.proj <class 'torch.nn.modules.linear.Linear'>
blocks.3.norm2 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.3.mlp <class 'vision_transformer.Mlp'>
blocks.3.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>
blocks.3.mlp.act <class 'torch.nn.modules.activation.GELU'>
blocks.3.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>
blocks.4.norm1 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.4.attn <class 'vision_transformer.Attention'>
blocks.4.attn.qkv <class 'torch.nn.modules.linear.Linear'>
blocks.4.attn.proj <class 'torch.nn.modules.linear.Linear'>
blocks.4.norm2 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.4.mlp <class 'vision_transformer.Mlp'>
blocks.4.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>
blocks.4.mlp.act <class 'torch.nn.modules.activation.GELU'>
blocks.4.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>
blocks.5.norm1 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.5.attn <class 'vision_transformer.Attention'>
blocks.5.attn.qkv <class 'torch.nn.modules.linear.Linear'>
blocks.5.attn.proj <class 'torch.nn.modules.linear.Linear'>
blocks.5.norm2 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.5.mlp <class 'vision_transformer.Mlp'>
blocks.5.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>
blocks.5.mlp.act <class 'torch.nn.modules.activation.GELU'>
blocks.5.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>
blocks.6.norm1 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.6.attn <class 'vision_transformer.Attention'>
blocks.6.attn.qkv <class 'torch.nn.modules.linear.Linear'>
blocks.6.attn.proj <class 'torch.nn.modules.linear.Linear'>
blocks.6.norm2 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.6.mlp <class 'vision_transformer.Mlp'>
blocks.6.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>
blocks.6.mlp.act <class 'torch.nn.modules.activation.GELU'>
blocks.6.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>
blocks.7.norm1 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.7.attn <class 'vision_transformer.Attention'>
blocks.7.attn.qkv <class 'torch.nn.modules.linear.Linear'>
blocks.7.attn.proj <class 'torch.nn.modules.linear.Linear'>
blocks.7.norm2 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.7.mlp <class 'vision_transformer.Mlp'>
blocks.7.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>
blocks.7.mlp.act <class 'torch.nn.modules.activation.GELU'>
blocks.7.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>
blocks.8.norm1 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.8.attn <class 'vision_transformer.Attention'>
blocks.8.attn.qkv <class 'torch.nn.modules.linear.Linear'>
blocks.8.attn.proj <class 'torch.nn.modules.linear.Linear'>
blocks.8.norm2 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.8.mlp <class 'vision_transformer.Mlp'>
blocks.8.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>
blocks.8.mlp.act <class 'torch.nn.modules.activation.GELU'>
blocks.8.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>
blocks.9.norm1 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.9.attn <class 'vision_transformer.Attention'>
blocks.9.attn.qkv <class 'torch.nn.modules.linear.Linear'>
blocks.9.attn.proj <class 'torch.nn.modules.linear.Linear'>
blocks.9.norm2 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.9.mlp <class 'vision_transformer.Mlp'>
blocks.9.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>
blocks.9.mlp.act <class 'torch.nn.modules.activation.GELU'>
blocks.9.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>
blocks.10.norm1 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.10.attn <class 'vision_transformer.Attention'>
blocks.10.attn.qkv <class 'torch.nn.modules.linear.Linear'>
blocks.10.attn.proj <class 'torch.nn.modules.linear.Linear'>
blocks.10.norm2 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.10.mlp <class 'vision_transformer.Mlp'>
blocks.10.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>
blocks.10.mlp.act <class 'torch.nn.modules.activation.GELU'>
blocks.10.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>
blocks.11.norm1 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.11.attn <class 'vision_transformer.Attention'>
blocks.11.attn.qkv <class 'torch.nn.modules.linear.Linear'>
blocks.11.attn.proj <class 'torch.nn.modules.linear.Linear'>
blocks.11.norm2 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.11.mlp <class 'vision_transformer.Mlp'>
blocks.11.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>
blocks.11.mlp.act <class 'torch.nn.modules.activation.GELU'>
blocks.11.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>
blocks.0.norm1 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.0.attn <class 'timm.models.vision_transformer.Attention'>
blocks.0.attn.qkv <class 'torch.nn.modules.linear.Linear'>
blocks.0.attn.proj <class 'torch.nn.modules.linear.Linear'>
blocks.0.norm2 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.0.mlp <class 'timm.models.layers.mlp.Mlp'>
blocks.0.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>
blocks.0.mlp.act <class 'torch.nn.modules.activation.GELU'>
blocks.0.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>
blocks.1.norm1 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.1.attn <class 'timm.models.vision_transformer.Attention'>
blocks.1.attn.qkv <class 'torch.nn.modules.linear.Linear'>
blocks.1.attn.proj <class 'torch.nn.modules.linear.Linear'>
blocks.1.norm2 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.1.mlp <class 'timm.models.layers.mlp.Mlp'>
blocks.1.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>
blocks.1.mlp.act <class 'torch.nn.modules.activation.GELU'>
blocks.1.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>
blocks.2.norm1 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.2.attn <class 'timm.models.vision_transformer.Attention'>
blocks.2.attn.qkv <class 'torch.nn.modules.linear.Linear'>
blocks.2.attn.proj <class 'torch.nn.modules.linear.Linear'>
blocks.2.norm2 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.2.mlp <class 'timm.models.layers.mlp.Mlp'>
blocks.2.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>
blocks.2.mlp.act <class 'torch.nn.modules.activation.GELU'>
blocks.2.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>
blocks.3.norm1 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.3.attn <class 'timm.models.vision_transformer.Attention'>
blocks.3.attn.qkv <class 'torch.nn.modules.linear.Linear'>
blocks.3.attn.proj <class 'torch.nn.modules.linear.Linear'>
blocks.3.norm2 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.3.mlp <class 'timm.models.layers.mlp.Mlp'>
blocks.3.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>
blocks.3.mlp.act <class 'torch.nn.modules.activation.GELU'>
blocks.3.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>
blocks.4.norm1 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.4.attn <class 'timm.models.vision_transformer.Attention'>
blocks.4.attn.qkv <class 'torch.nn.modules.linear.Linear'>
blocks.4.attn.proj <class 'torch.nn.modules.linear.Linear'>
blocks.4.norm2 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.4.mlp <class 'timm.models.layers.mlp.Mlp'>
blocks.4.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>
blocks.4.mlp.act <class 'torch.nn.modules.activation.GELU'>
blocks.4.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>
blocks.5.norm1 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.5.attn <class 'timm.models.vision_transformer.Attention'>
blocks.5.attn.qkv <class 'torch.nn.modules.linear.Linear'>
blocks.5.attn.proj <class 'torch.nn.modules.linear.Linear'>
blocks.5.norm2 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.5.mlp <class 'timm.models.layers.mlp.Mlp'>
blocks.5.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>
blocks.5.mlp.act <class 'torch.nn.modules.activation.GELU'>
blocks.5.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>
blocks.6.norm1 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.6.attn <class 'timm.models.vision_transformer.Attention'>
blocks.6.attn.qkv <class 'torch.nn.modules.linear.Linear'>
blocks.6.attn.proj <class 'torch.nn.modules.linear.Linear'>
blocks.6.norm2 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.6.mlp <class 'timm.models.layers.mlp.Mlp'>
blocks.6.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>
blocks.6.mlp.act <class 'torch.nn.modules.activation.GELU'>
blocks.6.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>
blocks.7.norm1 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.7.attn <class 'timm.models.vision_transformer.Attention'>
blocks.7.attn.qkv <class 'torch.nn.modules.linear.Linear'>
blocks.7.attn.proj <class 'torch.nn.modules.linear.Linear'>
blocks.7.norm2 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.7.mlp <class 'timm.models.layers.mlp.Mlp'>
blocks.7.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>
blocks.7.mlp.act <class 'torch.nn.modules.activation.GELU'>
blocks.7.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>
blocks.8.norm1 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.8.attn <class 'timm.models.vision_transformer.Attention'>
blocks.8.attn.qkv <class 'torch.nn.modules.linear.Linear'>
blocks.8.attn.proj <class 'torch.nn.modules.linear.Linear'>
blocks.8.norm2 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.8.mlp <class 'timm.models.layers.mlp.Mlp'>
blocks.8.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>
blocks.8.mlp.act <class 'torch.nn.modules.activation.GELU'>
blocks.8.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>
blocks.9.norm1 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.9.attn <class 'timm.models.vision_transformer.Attention'>
blocks.9.attn.qkv <class 'torch.nn.modules.linear.Linear'>
blocks.9.attn.proj <class 'torch.nn.modules.linear.Linear'>
blocks.9.norm2 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.9.mlp <class 'timm.models.layers.mlp.Mlp'>
blocks.9.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>
blocks.9.mlp.act <class 'torch.nn.modules.activation.GELU'>
blocks.9.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>
blocks.10.norm1 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.10.attn <class 'timm.models.vision_transformer.Attention'>
blocks.10.attn.qkv <class 'torch.nn.modules.linear.Linear'>
blocks.10.attn.proj <class 'torch.nn.modules.linear.Linear'>
blocks.10.norm2 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.10.mlp <class 'timm.models.layers.mlp.Mlp'>
blocks.10.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>
blocks.10.mlp.act <class 'torch.nn.modules.activation.GELU'>
blocks.10.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>
blocks.11.norm1 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.11.attn <class 'timm.models.vision_transformer.Attention'>
blocks.11.attn.qkv <class 'torch.nn.modules.linear.Linear'>
blocks.11.attn.proj <class 'torch.nn.modules.linear.Linear'>
blocks.11.norm2 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.11.mlp <class 'timm.models.layers.mlp.Mlp'>
blocks.11.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>
blocks.11.mlp.act <class 'torch.nn.modules.activation.GELU'>
blocks.11.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>
blocks.0.norm1 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.0.attn <class 'timm.models.vision_transformer.Attention'>
blocks.0.attn.qkv <class 'torch.nn.modules.linear.Linear'>
blocks.0.attn.proj <class 'torch.nn.modules.linear.Linear'>
blocks.0.norm2 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.0.mlp <class 'timm.models.layers.mlp.Mlp'>
blocks.0.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>
blocks.0.mlp.act <class 'torch.nn.modules.activation.GELU'>
blocks.0.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>
blocks.1.norm1 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.1.attn <class 'timm.models.vision_transformer.Attention'>
blocks.1.attn.qkv <class 'torch.nn.modules.linear.Linear'>
blocks.1.attn.proj <class 'torch.nn.modules.linear.Linear'>
blocks.1.norm2 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.1.mlp <class 'timm.models.layers.mlp.Mlp'>
blocks.1.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>
blocks.1.mlp.act <class 'torch.nn.modules.activation.GELU'>
blocks.1.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>
blocks.2.norm1 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.2.attn <class 'timm.models.vision_transformer.Attention'>
blocks.2.attn.qkv <class 'torch.nn.modules.linear.Linear'>
blocks.2.attn.proj <class 'torch.nn.modules.linear.Linear'>
blocks.2.norm2 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.2.mlp <class 'timm.models.layers.mlp.Mlp'>
blocks.2.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>
blocks.2.mlp.act <class 'torch.nn.modules.activation.GELU'>
blocks.2.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>
blocks.3.norm1 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.3.attn <class 'timm.models.vision_transformer.Attention'>
blocks.3.attn.qkv <class 'torch.nn.modules.linear.Linear'>
blocks.3.attn.proj <class 'torch.nn.modules.linear.Linear'>
blocks.3.norm2 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.3.mlp <class 'timm.models.layers.mlp.Mlp'>
blocks.3.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>
blocks.3.mlp.act <class 'torch.nn.modules.activation.GELU'>
blocks.3.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>
blocks.4.norm1 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.4.attn <class 'timm.models.vision_transformer.Attention'>
blocks.4.attn.qkv <class 'torch.nn.modules.linear.Linear'>
blocks.4.attn.proj <class 'torch.nn.modules.linear.Linear'>
blocks.4.norm2 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.4.mlp <class 'timm.models.layers.mlp.Mlp'>
blocks.4.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>
blocks.4.mlp.act <class 'torch.nn.modules.activation.GELU'>
blocks.4.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>
blocks.5.norm1 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.5.attn <class 'timm.models.vision_transformer.Attention'>
blocks.5.attn.qkv <class 'torch.nn.modules.linear.Linear'>
blocks.5.attn.proj <class 'torch.nn.modules.linear.Linear'>
blocks.5.norm2 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.5.mlp <class 'timm.models.layers.mlp.Mlp'>
blocks.5.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>
blocks.5.mlp.act <class 'torch.nn.modules.activation.GELU'>
blocks.5.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>
blocks.6.norm1 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.6.attn <class 'timm.models.vision_transformer.Attention'>
blocks.6.attn.qkv <class 'torch.nn.modules.linear.Linear'>
blocks.6.attn.proj <class 'torch.nn.modules.linear.Linear'>
blocks.6.norm2 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.6.mlp <class 'timm.models.layers.mlp.Mlp'>
blocks.6.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>
blocks.6.mlp.act <class 'torch.nn.modules.activation.GELU'>
blocks.6.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>
blocks.7.norm1 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.7.attn <class 'timm.models.vision_transformer.Attention'>
blocks.7.attn.qkv <class 'torch.nn.modules.linear.Linear'>
blocks.7.attn.proj <class 'torch.nn.modules.linear.Linear'>
blocks.7.norm2 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.7.mlp <class 'timm.models.layers.mlp.Mlp'>
blocks.7.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>
blocks.7.mlp.act <class 'torch.nn.modules.activation.GELU'>
blocks.7.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>
blocks.8.norm1 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.8.attn <class 'timm.models.vision_transformer.Attention'>
blocks.8.attn.qkv <class 'torch.nn.modules.linear.Linear'>
blocks.8.attn.proj <class 'torch.nn.modules.linear.Linear'>
blocks.8.norm2 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.8.mlp <class 'timm.models.layers.mlp.Mlp'>
blocks.8.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>
blocks.8.mlp.act <class 'torch.nn.modules.activation.GELU'>
blocks.8.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>
blocks.9.norm1 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.9.attn <class 'timm.models.vision_transformer.Attention'>
blocks.9.attn.qkv <class 'torch.nn.modules.linear.Linear'>
blocks.9.attn.proj <class 'torch.nn.modules.linear.Linear'>
blocks.9.norm2 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.9.mlp <class 'timm.models.layers.mlp.Mlp'>
blocks.9.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>
blocks.9.mlp.act <class 'torch.nn.modules.activation.GELU'>
blocks.9.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>
blocks.10.norm1 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.10.attn <class 'timm.models.vision_transformer.Attention'>
blocks.10.attn.qkv <class 'torch.nn.modules.linear.Linear'>
blocks.10.attn.proj <class 'torch.nn.modules.linear.Linear'>
blocks.10.norm2 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.10.mlp <class 'timm.models.layers.mlp.Mlp'>
blocks.10.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>
blocks.10.mlp.act <class 'torch.nn.modules.activation.GELU'>
blocks.10.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>
blocks.11.norm1 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.11.attn <class 'timm.models.vision_transformer.Attention'>
blocks.11.attn.qkv <class 'torch.nn.modules.linear.Linear'>
blocks.11.attn.proj <class 'torch.nn.modules.linear.Linear'>
blocks.11.norm2 <class 'torch.nn.modules.normalization.LayerNorm'>
blocks.11.mlp <class 'timm.models.layers.mlp.Mlp'>
blocks.11.mlp.fc1 <class 'torch.nn.modules.linear.Linear'>
blocks.11.mlp.act <class 'torch.nn.modules.activation.GELU'>
blocks.11.mlp.fc2 <class 'torch.nn.modules.linear.Linear'>
